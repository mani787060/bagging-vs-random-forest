# Bagging vs Random Forest

This project demonstrates and compares two popular ensemble learning techniques:
**Bagging Classifier** and **Random Forest Classifier**.

The goal is to understand how both methods work, how they differ internally, and how their performance compares on the same dataset.

---

## Concepts Covered
- Ensemble Learning
- Bagging (Bootstrap Aggregating)
- Random Forest
- Biasâ€“Variance Tradeoff
- Model Comparison

---

## Algorithms Used
- Bagging Classifier (with Decision Trees as base estimators)
- Random Forest Classifier

---

## Workflow
1. Load and preprocess the dataset  
2. Train a Bagging Classifier  
3. Train a Random Forest Classifier  
4. Compare performance metrics  
5. Analyze results and observations  

---

## Evaluation Metrics
- Accuracy Score
- Training vs Testing performance comparison

---

## Libraries Used
- Python
- NumPy
- Pandas
- Scikit-learn
- Matplotlib (if visualization is included)
